## linux方面，linux系统怎么启动，分几个步骤，linux下查看进程怎么操作   
https://www.runoob.com/linux/linux-system-boot.html   
1.内核的引导。
当计算机打开电源后，首先是BIOS开机自检，按照BIOS中设置的启动设备（通常是硬盘）来启动。    
操作系统接管硬件以后，首先读入 /boot 目录下的内核文件。     
2.运行 init。   
init 进程是系统所有进程的起点，你可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。   
init 程序首先是需要读取配置文件 /etc/inittab。     
3.系统初始化。      
它主要完成的工作有：激活交换分区，检查磁盘，加载硬件模块以及其它一些需要优先执行任务。     
4.建立终端 。     
init接下来会打开6个终端，以便用户登录系统。在inittab中的以下6行就是定义了6个终端：    
5.用户登录系统。   

## linux 用户空间 内核空间  
Linux 操作系统和驱动程序运行在内核空间，应用程序运行在用户空间  

os分配给每个进程一个独立的、连续的、虚拟的地址内存空间，该大小一般是4G（32位操作系统，即2的32次方），其中将高地址值的内存空间分配给os占用，linux os占用1G，window os占用2G；其余内存地址空间分配给进程使用。   

进程寻址空间0—4G    
进程在用户态只能访问0-3G，只有进入内核态才能访问3G-4G       
进程通过系统调用进入内核态      
每个进程虚拟空间的3G-4G部分是相同的        


1、用户空间（进程）是否有高端内存概念？   

用户进程没有高端内存概念。只有在内核空间才存在高端内存。用户进程最多只可以访问3G物理内存，而内核进程可以访问所有物理内存。   

2、64位内核中有高端内存吗？   

目前现实中，64位Linux内核不存在高端内存，因为64位内核可以支持超过512GB内存。若机器安装的物理内存超过内核地址空间范围，就会存在高端内存。  

3、用户进程能访问多少物理内存？内核代码能访问多少物理内存？  

32位系统用户进程最大可以访问3GB，内核代码可以访问所有物理内存。  

64位系统用户进程最大可以访问超过512GB，内核代码可以访问所有物理内存。   

4、高端内存和物理地址、逻辑地址、线性地址的关系？   

高端内存只和逻辑地址有关系，和逻辑地址、物理地址没有直接关系。   

## 虚拟内存怎样转到物理内存
https://blog.csdn.net/lvyibin890/article/details/82217193     
操作系统有虚拟内存与物理内存的概念。在很久以前，还没有虚拟内存概念的时候，程序寻址用的都是物理地址。程序能寻址的范围是有限的，这取决于CPU的地址线条数。比如在32位平台下，寻址的范围是2^32也就是4G。并且这是固定的，如果没有虚拟内存，且每次开启一个进程都给4G的物理内存，就可能会出现很多问题：  

1.因为我的物理内存时有限的，当有多个进程要执行的时候，都要给4G内存，很显然你内存小一点，这很快就分配完了，于是没有得到分配资源的进程就只能等待。当一个进程执行完了以后，再将等待的进程装入内存。这种频繁的装入内存的操作是很没效率的      
2.由于指令都是直接访问物理内存的，那么我这个进程就可以修改其他进程的数据，甚至会修改内核地址空间的数据，这是我们不想看到的     
3.因为内存时随机分配的，所以程序运行的地址也是不正确的。       

一个进程运行时都会得到4G的虚拟内存。这个虚拟内存你可以认为，每个进程都认为自己拥有4G的空间，这只是每个进程认为的，但是实际上，在虚拟内存对应的物理内存上，可能只对应的一点点的物理内存，实际用了多少内存，就会对应多少物理内存。     
进程得到的这4G虚拟内存是一个连续的地址空间（这也只是进程认为），而实际上，它通常是被分隔成多个物理内存碎片，还有一部分存储在外部磁盘存储器上，在需要时进行数据交换。  

进程开始要访问一个地址，它可能会经历下面的过程

1.每次我要访问地址空间上的某一个地址，都需要把地址翻译为实际物理内存地址   
2.所有进程共享这整一块物理内存，每个进程只把自己目前需要的虚拟地址空间映射到物理内存上   
3.进程需要知道哪些地址空间上的数据在物理内存上，哪些不在（可能这部分存储在磁盘上），还有在物理内存上的哪里，这就需要通过页表来记录   
4.页表的每一个表项分两部分，第一部分记录此页是否在物理内存上，第二部分记录物理内存页的地址（如果在的话）   
5.当进程访问某个虚拟地址的时候，就会先去看页表，如果发现对应的数据不在物理内存上，就会发生缺页异常    
6.缺页异常的处理过程，操作系统立即阻塞该进程，并将硬盘里对应的页换入内存，然后使该进程就绪，如果内存已经满了，没有空地方了，那就找一个页覆盖，至于具体覆盖的哪个页，就需要看操作系统的页面置换算法是怎么设计的了。   

再来总结一下虚拟内存是怎么工作的    
当每个进程创建的时候，内核会为进程分配4G的虚拟内存，当进程还没有开始运行时，这只是一个内存布局。实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射）。这个时候数据和代码还是在磁盘上的。当运行到对应的程序时，进程去寻找页表，发现页表中地址没有存放在物理内存上，而是在磁盘上，于是发生缺页异常，于是将磁盘上的数据拷贝到物理内存中。    
另外在进程运行过程中，要通过malloc来动态分配内存时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。   
可以认为虚拟空间都被映射到了磁盘空间中（事实上也是按需要映射到磁盘空间上，通过mmap，mmap是用来建立虚拟空间和磁盘空间的映射关系的）    

## Linux线程模型有哪些     
线程的实现曾有3种模型：      
1.多对一(M:1)的用户级线程模型       
2.一对一(1:1)的内核级线程模型       
3.多对多(M:N)的两级线程模型       

最开始使用的线程是LinuxThreads  一对一       
后来IBM开发了NGPT(Next Generation POSIX Threads)   多对多    
我们现在用的Linux线程就是NPTL   一对一   

多对一用户线级程模型                          
多对一线程模型中，线程的创建、调度、同步的所有细节全部由进程的用户空间线程库来处理。用户态线程的很多操作对内核来说都是透明的，因为不需要内核来接管，这意味不需要内核态和用户态频繁切换。线程的创建、调度、同步处理速度非常快。当然线程的一些其他操作还是要经过内核，如IO读写。这样导致了一个问题：当多线程并发执行时，如果其中一个线程执行IO操作时，内核接管这个操作，如果IO阻塞，用户态的其他线程都会被阻塞，因为这些线程都对应同一个内核调度实体。在多处理器机器上，内核不知道用户态有这些线程，无法把它们调度到其他处理器，也无法通过优先级来调度。这对线程的使用是没有意义的！   

一对一内核极线程模型                         
一对一模型中，每个用户线程都对应各自的内核调度实体。内核会对每个线程进行调度，可以调度到其他处理器上面。当然由内核来调度的结果就是：线程的每次操作会在用户态和内核态切换。另外，内核为每个线程都映射调度实体，如果系统出现大量线程，会对系统性能有影响。但该模型的实用性还是高于多对一的线程模型。   

多对多两极线程模型                             
多对多模型中，结合了1：1和M：1的优点，避免了它们的缺点。每个线程可以拥有多个调度实体，也可以多个线程对应一个调度实体。听起来好像非常完美，但线程的调度需要由内核态和用户态一起来实现。可想而知，多个对象操作一个东西时，肯定要一些其他的同步机制。用户态和内核态的分工合作导致实现该模型非常复杂。NPTL曾经也想使用该模型，但它太复杂，要对内核进行大范围改动，所以还是采用了一对一的模型！！！    

## linux的进程调度策略，
原文链接：https://blog.csdn.net/MrCoderStack/article/details/88547997

Linux进程的进程级别分类    
普通进程    
实时进程    

实时进程   
硬实时    
实时，原本的涵义是“给定的操作一定要在确定的时间内完成”。重点并不在于操作一定要处理得多快，而是时间要可控（在最坏情况下也不能突破给定的时间）。    
这样的“实时”称为“硬实时”，多用于很精密的系统之中（比如什么火箭、导弹之类的）。一般来说，硬实时的系统是相对比较专用的。   

软实时
linux实现的是“软实时”，即尽可能地满足进程的实时需求。    

实时进程的调度      
优先级策略      

先进先出策略        
SCHED_FIFO：先进先出。直到先被执行的进程变为非可执行状态，后来的进程才被调度执行。在这种策略下，先来的进程可以执行sched_yield系统调用，自愿放弃CPU，以让权给后来的进程；        

轮转策略     
SCHED_RR：轮转。内核为实时进程分配时间片，在时间片用完时，让下一个进程使用CPU；       
再次强调一下，这两种调度策略仅仅针对于相同优先级的多个实时进程同时处于可执行状态的情况        

普通进程的调度
实时进程调度的中心思想是，让处于可执行状态的最高优先级的实时进程尽可能地占有CPU，因为它有实时需求；而普通进程则被认为是没有实时需求的进程，于是调度程序力图让各个处于可执行状态的普通进程和平共处地分享CPU，从而让用户觉得这些进程是同时运行的。与实时进程相比，普通进程的调度要复杂得多。内核需要考虑两件麻烦事：  

交互式进程   
如桌面程序、服务器、等，主要的任务是与外界交互。这样的进程应该具有较高的优先级，它们总是睡眠等待外界的输入。而在输入到来，内核将其唤醒时，它们又应该很快被调度执行，以做出响应。比如一个桌面程序，如果鼠标点击后半秒种还没反应，用户就会感觉系统“卡”了；   

批处理进程    
如编译程序，主要的任务是做持续的运算，因而它们会持续处于可执行状态。这样的进程一般不需要高优先级，比如编译程序多运行了几秒种，用户多半不会太在意；   

调度程序关注进程近一段时间内的表现（主要是检查其睡眠时间和运行时间），根据一些经验性的公式，判断它现在是交互式的还是批处理的？程度如何？最后决定给它的优先级做一定的调整。    

##调度的公平性

在支持多进程的系统中，理想情况下，各个进程应该是根据其优先级公平地占有CPU。而不会出现“谁运气好谁占得多”这样的不可控的情况。

linux实现公平调度基本上是两种思路：
1.给处于可执行状态的进程分配时间片（按照优先级），用完时间片的进程被放到“过期队列”中。等可执行状态的进程都过期了，再重新分配时间片；     
2.动态调整进程的优先级。随着进程在CPU上运行，其优先级被不断调低，以便其他优先级较低的进程得到运行机会；     
后一种方式有更小的调度粒度，并且将“公平性”与“动态调整优先级”两件事情合而为一，大大简化了内核调度程序的代码。因此，这种方式也成为内核调度程序的新宠。

强调一下，以上两点都是仅针对普通进程的。而对于实时进程，内核既不能自作多情地去动态调整优先级，也没有什么公平性可言  

## tcp拥塞控制的原理，以及采取的各种方法，tcp的流量控制是如何实现的，什么是滑动窗口，   
原文链接：https://blog.csdn.net/u013743253/article/details/80293911    

发生拥塞控制的原因：资源的需求>可用资源   

作用：拥塞控制就是防止过多的数据包进入网络，这样可以使网络中的路由器或者链路不至于过载。拥塞控制的前提就是网络能够承受现有的网络负荷。   

对比流量控制：拥塞控制是一个全局的过程，涉及到链路上的所有主机和路由。   

流量控制往往指的是点对点通信的控制，是端对端的问题。   

流量控制：  

（1）tcp提供了一种机制可以让发送端根据接收端的实际接收能力来控制发送的速率，具体的操作是接收端主机向发送端主机通知自己可以接收数据的大小，于是发送会发送不超过这个限度的数据，该限度大小就被称为窗口大小。   

（2）TCP首部中专门有个字段用来通知窗口大小，接收主机将自己可以接收缓冲区的大小放入这个字段通知发送端。这个字段越大说明网络的吞吐量越大。   

（3）接收端缓冲区一旦面临溢出，窗口大小也会随之被设置为一个更小的值发送给发送端，从而控制发送的数据量，也就说发送端主机会根据接收端主机的缓冲区大小来对发送数据的大小进行控制。   

拥塞控制：

计算机网络是一个共享网络，有可能因为其他主机间的通信造成网络拥堵，在网络出现拥堵时，如果突然发送一个较大的数据包可能导致整个网络的瘫痪。

拥塞窗口：发送方为一个动态变化的窗口叫做拥塞窗口，拥塞窗口的大小取决于网络的拥塞程度。发送让自己的发送窗口=MIN（拥塞窗口，接收方的接收窗口），但是发送窗口不是一直等于拥塞窗口，在网络情况好的情况下，拥塞窗口会不断增加，发送方的窗口自然也会随着增加，但是接收方的能力有限，在发送方的窗口达到某个大小时就不在发生变化了。

发送方如果确认网络拥塞：发送方发送一些报文时，如果发送没有在规定的时间间隔内收到接收方的应答，则就可以认为网络拥塞。      

拥塞避免的思路：     

（1）最初让拥塞窗口按照指数级增长，这样可以提高发送数据吞吐量；      

（2）当拥塞窗口大小到达慢启动门限后，该成线性增长，目的是减少拥塞窗口的增长速度；       

（3）当发送端检测的网络拥塞时，立即把拥塞窗口减小为1，把慢启动门限调整为出现拥塞时拥塞窗口的一半目的是可以减少向网络中注入的数据量。        

（4）重新开始指数级增长和线性增长。      

## linux是如何寻址的    

在操作系统中，存在着这样的三个地址概念，他们是逻辑地址、线性地址和物理地址   

逻辑地址：包含在机器语言中，用来指定一个操作数或者一条指令的地址。每一个逻辑地址都由一个段和偏移量组成，偏移量指明了他从段开始的地址到实际地址的距离； 
线性地址：也称作虚拟地址，是一个32位的无符号整数（32位操作系统），可以表达4GB的地址空间。其地址用十六禁止的数字表示，值得范围从0x00000000到0xffffffff。   
物理地址：用于内存单元的寻址，是真正的内存的地址。    

内存控制单元（MMU）通过分段单元的硬件电路把一个逻辑地址转换为线性地址；接着通过分页单元的硬件电路把线性地址转换为一个物理地址（如图1.1）。  

逻辑地址 -》 线性地址  -》  物理地址       

分页单元把得到的线性地址转换成物理地址。其中一个关键的任务是把请求的访问类型与线性地址的访问权限相比较，如果这次内存访问是无效的，就产生一个缺页异常。为了提高效率，线性地址被分成固定长度的单元组，称之为页，页内部连续的线性地址映射到连续的物理地址中。因此，内核可以指定一个页的物理地址和他的存取权限，而不用指定页包含的全部地址的存取权限。      

## c++对象内存如何布局的      


## Linux用过哪些命令，安装一个软件需要哪些命令；
https://www.cnblogs.com/caozy/p/9261224.html      

## 用宏实现判断大小的函数    

#define MAX(a, b) (a) > (b) ? printf("a > b") : printf("a < b")   

## 数据库的特性    

## 数据库索引，什么是索引，如何证明索引是有效的     

1.比较频繁的作为查询的字段     

2.唯一性太差的字段不适合加索引，要找唯一性比较好的      

3.更新太频繁的字段不适合做索引     

4.不会出现在where中的 不应该建立索引       

## socket通信过程

原文链接：https://blog.csdn.net/upupday19/article/details/78916142   

传统的TCP/IP通信过程依赖于socket，位于应用层和传输层之间，使得应用程序可以进行通信。相当于港口城市的码头，使得城市之间可以进行货物流通。服务器和客户端各有不同的通信流程。   

一、服务器  
    1、建立连接阶段   

调用socket()，分配文件描述符，即监听套接字   
调用bind()，将套接字与本地IP地址和端口绑定   
调用listen()，监听特定端口，socket()创建的套接字是主动的，调用listen使得该文件描述符为监听套接字，变主动为被动   
调用accept()，阻塞等待客户端连接   
    2、数据交互阶段   

调用read()，阻塞等待客户端发送的请求，收到请求后从read()返回，处理客户端请求   
调用write()，将处理结果发送给客户端，然后继续调用read()等待客户端请求   
    3、关闭连接   

当read()返回0的时候，说明客户端发来了FIN数据包，即关闭连接，也会调用close()关闭连接套接字和监听套接字   

二、客户端   
    1、建立连接阶段   

调用socket()，分配文件描述符   
调用connect()，向服务器发送建立连接请求  
    2、数据交互阶段   

调用write()，将请求发送给服务器   
调用read()，阻塞等待服务器应答   
    3、关闭连接    

当没有数据发送的时候，调用close()关闭连接套接字，即关闭连接，向服务器发送FIN数据报    

## 代理模式     

## truncat、drop、delete区别   

一、delete   

1、delete是DML，执行delete操作时，每次从表中删除一行，并且同时将该行的的删除操作记录在redo和undo表空间中以便进行回滚（rollback）和重做操作，但要注意表空间要足够大，需要手动提交（commit）操作才能生效，可以通过rollback撤消操作。  

2、delete可根据条件删除表中满足条件的数据，如果不指定where子句，那么删除表中所有记录。   

3、delete语句不影响表所占用的extent，高水线(high watermark)保持原位置不变。  

二、truncate    

1、truncate是DDL，会隐式提交，所以，不能回滚，不会触发触发器。   

2、truncate会删除表中所有记录，并且将重新设置高水线和所有的索引，缺省情况下将空间释放到minextents个extent，除非使用reuse storage，。不会记录日志，所以执行速度很快，但不能通过rollback撤消操作（如果一不小心把一个表truncate掉，也是可以恢复的，只是不能通过rollback来恢复）。   

3、对于外键（foreignkey ）约束引用的表，不能使用 truncate table，而应使用不带 where 子句的 delete 语句。    

4、truncatetable不能用于参与了索引视图的表。   

三、drop    

1、drop是DDL，会隐式提交，所以，不能回滚，不会触发触发器。   

2、drop语句删除表结构及所有数据，并将表所占用的空间全部释放。   

3、drop语句将删除表的结构所依赖的约束，触发器，索引，依赖于该表的存储过程/函数将保留,但是变为invalid状态。   

## http是基于tcp还是udp    
无关   

## arp协议是那一层的协议    
链路层     

## Web页面请求过程；

## 判断链表是否环
set   快慢指针   
## malloc/free的底层实现
malloc()到底从哪里得到了内存空间？答案是从堆里面获得空间。也就是说函数返回的指针是指向堆里面的一块内存。操作系统中有一个记录空闲内存地址的链表。当操作系统收到程序的申请时，就会遍历该链表，然后就寻找第一个空间大于所申请空间的堆结点，然后就将该结点从空闲结点链表中删除，并将该结点的空间分配给程序。    
## 输入网址后，网络中怎样通信的流程（到黑板上画出来）

## 深复制和浅复制是怎么处理的；


